---
title: AI & LLM Integration
description: Access Avalanche documentation programmatically for AI applications
icon: Bot
---

The Builder Hub provides AI-friendly access to documentation through standardized formats. Whether you're building a chatbot, using Claude/ChatGPT, or integrating with AI development tools, we offer multiple ways to access our docs.

## Endpoints Overview

| Endpoint | Purpose |
| :------- | :------ |
| `/llms.txt` | AI sitemap - structured index of all documentation |
| `/llms-full.txt` | Complete docs in one file for full context loading |
| `/api/llms/page?path=...` | Fetch any single page as markdown |
| `/api/mcp` | MCP server for dynamic search and retrieval |

## llms.txt

A structured markdown index following the [llms.txt standard](https://llmstxt.org/). Use this for content discovery.

```
https://build.avax.network/llms.txt
```

Returns organized sections (Documentation, Academy, Integrations, Blog) with links and descriptions.

## llms-full.txt

All documentation content in a single markdown file for one-time context loading.

```
https://build.avax.network/llms-full.txt
```

Contains 1300+ pages. For models with limited context, use the MCP server or individual page endpoint instead.

## Individual Pages

Fetch any page as markdown:

```
https://build.avax.network/api/llms/page?path=/docs/primary-network/overview
https://build.avax.network/api/llms/page?path=/academy/blockchain-fundamentals/blockchain-intro
```

Supports `/docs/`, `/academy/`, `/integrations/`, and `/blog/` paths.

## MCP Server

The [Model Context Protocol](https://modelcontextprotocol.io/) server enables AI systems to search and retrieve documentation dynamically.

**Endpoint:** `https://build.avax.network/api/mcp`

### Tools

| Tool | Purpose |
| :--- | :------ |
| `avalanche_docs_search` | Search docs by query with optional source filter |
| `avalanche_docs_fetch` | Get a specific page by URL path |
| `avalanche_docs_list_sections` | List all sections with page counts |

### Claude Code Setup

Add the MCP server to your project:

```bash
claude mcp add avalanche-docs --transport http --url https://build.avax.network/api/mcp
```

Or add to your `.claude/settings.json`:

```json
{
  "mcpServers": {
    "avalanche-docs": {
      "transport": {
        "type": "http",
        "url": "https://build.avax.network/api/mcp"
      }
    }
  }
}
```

### Claude Desktop Setup

Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "avalanche-docs": {
      "transport": {
        "type": "http",
        "url": "https://build.avax.network/api/mcp"
      }
    }
  }
}
```

### JSON-RPC Protocol

The MCP server uses JSON-RPC 2.0 for communication:

```bash
curl -X POST https://build.avax.network/api/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","id":1,"method":"tools/call","params":{"name":"avalanche_docs_search","arguments":{"query":"create L1","limit":5}}}'
```

**Response format:**

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "[{\"title\":\"Create an L1\",\"url\":\"/docs/avalanche-l1s/create\",\"description\":\"...\",\"score\":45}]"
      }
    ]
  }
}
```

### Search Tool Examples

**Search all documentation:**

```bash
curl -X POST https://build.avax.network/api/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/call",
    "params": {
      "name": "avalanche_docs_search",
      "arguments": {
        "query": "smart contracts",
        "limit": 10
      }
    }
  }'
```

**Filter by source:**

```bash
# Search only academy content
curl -X POST https://build.avax.network/api/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 2,
    "method": "tools/call",
    "params": {
      "name": "avalanche_docs_search",
      "arguments": {
        "query": "blockchain basics",
        "source": "academy",
        "limit": 5
      }
    }
  }'
```

**Fetch specific page:**

```bash
curl -X POST https://build.avax.network/api/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 3,
    "method": "tools/call",
    "params": {
      "name": "avalanche_docs_fetch",
      "arguments": {
        "url": "/docs/primary-network/overview"
      }
    }
  }'
```

## Real-World Example: Builder Hub Chatbot

The Builder Hub chatbot demonstrates how to integrate the MCP server with modern AI SDKs. Here's how we built it:

### Architecture

The chatbot uses a two-layer approach for Edge Runtime compatibility:

1. **Chat Route** (`/app/api/chat/route.ts`) - Vercel AI SDK with tool calling
2. **Tool Definitions** (`/lib/chat-tools.ts`) - Wrapper around MCP server calls

This pattern is necessary because:
- Chat runs in Edge Runtime for performance
- MCP server uses Node.js modules (incompatible with Edge)
- HTTP calls between layers add minimal latency (same deployment)

### Tool Definitions with Vercel AI SDK

Here's how we define tools that call the MCP server:

```typescript
// /lib/chat-tools.ts
import { tool } from 'ai';
import { z } from 'zod';

// Helper to get base URL (works in Edge Runtime)
function getBaseUrl(): string {
  if (process.env.NEXT_PUBLIC_SITE_URL) {
    return process.env.NEXT_PUBLIC_SITE_URL;
  }
  if (process.env.VERCEL_URL) {
    return `https://${process.env.VERCEL_URL}`;
  }
  return 'http://localhost:3000';
}

// Helper to call MCP server via HTTP (Edge Runtime compatible)
async function callMcpTool(
  toolName: string,
  args: Record<string, unknown>
): Promise<unknown> {
  const baseUrl = getBaseUrl();
  const response = await fetch(`${baseUrl}/api/mcp`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      jsonrpc: '2.0',
      id: Date.now(),
      method: 'tools/call',
      params: {
        name: toolName,
        arguments: args,
      },
    }),
  });

  if (!response.ok) {
    throw new Error(`MCP call failed: ${response.status}`);
  }

  const result = await response.json();

  if (result.error) {
    throw new Error(result.error.message || 'MCP call failed');
  }

  // Extract text content from MCP response format
  if (result.result?.content?.[0]?.text) {
    return result.result.content[0].text;
  }

  return result.result;
}

// Define tools using AI SDK's tool() function
export const chatTools = {
  search_docs: tool({
    description:
      'Search Avalanche documentation, academy courses, integrations, and blog posts. Use this to find relevant pages for answering user questions. Returns URLs, titles, descriptions, and relevance scores.',
    parameters: z.object({
      query: z
        .string()
        .describe('The search query - use keywords from the user question'),
      source: z
        .enum(['docs', 'academy', 'integrations', 'blog'])
        .optional()
        .describe('Filter by source type. Omit to search all sources.'),
      limit: z
        .number()
        .min(1)
        .max(20)
        .optional()
        .describe('Maximum number of results to return. Default is 10.'),
    }),
    execute: async ({ query, source, limit }) => {
      try {
        const result = await callMcpTool('avalanche_docs_search', {
          query,
          source,
          limit: limit || 10,
        });
        return result;
      } catch (error) {
        return `Search failed: ${error instanceof Error ? error.message : 'Unknown error'}`;
      }
    },
  }),

  fetch_page: tool({
    description:
      'Fetch the full markdown content of a specific documentation page. Use this after searching to get detailed information from the most relevant results. Always use the path from search results.',
    parameters: z.object({
      url: z
        .string()
        .describe(
          'The page URL path from search results, e.g., /docs/primary-network/overview'
        ),
    }),
    execute: async ({ url }) => {
      try {
        const normalizedUrl = url.startsWith('/') ? url : `/${url}`;
        const result = await callMcpTool('avalanche_docs_fetch', {
          url: normalizedUrl,
        });

        // Truncate very long content to avoid token limits
        if (typeof result === 'string' && result.length > 15000) {
          return result.slice(0, 15000) + '\n\n[Content truncated due to length...]';
        }

        return result;
      } catch (error) {
        return `Page fetch failed: ${error instanceof Error ? error.message : 'Unknown error'}. Try using search_docs to find the correct page path.`;
      }
    },
  }),
};
```

### Chat Route Integration

The chat route uses these tools with the Vercel AI SDK:

```typescript
// /app/api/chat/route.ts
import { createOpenAI } from '@ai-sdk/openai';
import { streamText } from 'ai';
import { chatTools } from '@/lib/chat-tools';

export const runtime = 'edge';

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Simplified system prompt - tools handle document retrieval
const SYSTEM_PROMPT = `You are an expert AI assistant for Avalanche Builders Hub.

## CAPABILITIES

You have access to tools that let you search and fetch documentation:
- **search_docs**: Find relevant pages by keyword across docs, academy, integrations, and blog
- **fetch_page**: Get full markdown content of a specific page
- **list_sections**: See available documentation sections and page counts

## WORKFLOW

1. When a user asks a question, use **search_docs** to find relevant pages
2. Use **fetch_page** to get detailed content from the most relevant results (1-3 pages)
3. Synthesize information into a clear, accurate answer
4. Always cite sources with full URLs from the tool results

## URL RULES

- Base URL: https://build.avax.network
- Documentation: /docs/... | Academy: /academy/... | Integrations: /integrations/... | Blog: /blog/...
- Use EXACT URLs from search results - never modify, shorten, or guess URLs

## RESPONSE GUIDELINES

- **Be Direct**: Start with a clear answer
- **Cite Sources**: Include full URLs from tool results
- **Use Examples**: Include code snippets when helpful`;

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai('gpt-4o-mini'),
    messages: messages,
    tools: chatTools,
    maxSteps: 5, // Allow multi-step tool calling for search → fetch workflow
    system: SYSTEM_PROMPT,
  });

  return result.toDataStreamResponse();
}
```

### Key Benefits of This Pattern

1. **Edge Runtime Compatible** - HTTP calls work in Edge Runtime
2. **Type-Safe** - Zod schemas validate all tool parameters
3. **Efficient** - Only fetches content when needed (no more 3MB llms-full.txt loads)
4. **Smart** - LLM decides what to search/fetch based on context
5. **Maintainable** - System prompt reduced from ~450 lines to ~100 lines (87% reduction)

### The Search → Fetch Workflow

With `maxSteps: 5`, the LLM can:

1. **Receive user question**: "How do I create an L1?"
2. **Call search_docs**: Search for "create L1" in documentation
3. **Review results**: See titles, URLs, descriptions, and scores
4. **Call fetch_page**: Get full content of the most relevant page(s)
5. **Generate answer**: Synthesize information and cite sources

This is far more efficient than loading all 1300+ pages into context.

## Integration Patterns

### Pattern 1: Direct MCP Client (Node.js)

For Node.js applications, you can import MCP server functions directly:

```typescript
import { searchDocs, getPageContent } from '@/lib/mcp-server';

// Search documentation
const results = searchDocs('smart contracts', {
  source: 'docs',
  limit: 5,
});

// Fetch specific page
const content = await getPageContent('/docs/primary-network/overview');
```

**Pros:**
- Zero HTTP overhead
- Type-safe
- Works in Node.js environment

**Cons:**
- Not compatible with Edge Runtime
- Requires importing Node.js modules

### Pattern 2: HTTP Wrapper (Edge Runtime)

For Edge Runtime environments (like Vercel Edge Functions), use HTTP:

```typescript
// As shown in the chatbot example above
async function callMcpTool(toolName: string, args: Record<string, unknown>) {
  const response = await fetch(`${baseUrl}/api/mcp`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      jsonrpc: '2.0',
      id: Date.now(),
      method: 'tools/call',
      params: { name: toolName, arguments: args },
    }),
  });

  const result = await response.json();
  return result.result?.content?.[0]?.text || result.result;
}
```

**Pros:**
- Works in Edge Runtime
- Minimal latency (same deployment)
- Simple error handling

**Cons:**
- HTTP overhead (minimal for same-deployment calls)
- Requires handling JSON-RPC protocol

### Pattern 3: Python Integration

For Python applications using LangChain or similar:

```python
import requests

def call_mcp_tool(tool_name, args):
    response = requests.post(
        'https://build.avax.network/api/mcp',
        json={
            'jsonrpc': '2.0',
            'id': 1,
            'method': 'tools/call',
            'params': {
                'name': tool_name,
                'arguments': args
            }
        }
    )
    result = response.json()
    return result['result']['content'][0]['text']

# Search documentation
search_results = call_mcp_tool('avalanche_docs_search', {
    'query': 'create L1',
    'limit': 5
})

# Fetch specific page
page_content = call_mcp_tool('avalanche_docs_fetch', {
    'url': '/docs/avalanche-l1s/create'
})
```

## Error Handling

### HTTP Status Codes

- `200` - Success
- `400` - Invalid JSON-RPC request
- `404` - Page not found (for individual page endpoint)
- `500` - Server error

### JSON-RPC Error Codes

- `-32700` - Parse error (invalid JSON)
- `-32600` - Invalid request (missing required fields)
- `-32601` - Method not found
- `-32602` - Invalid params
- `-32603` - Internal error

**Example error response:**

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "error": {
    "code": -32602,
    "message": "Invalid params: query is required"
  }
}
```

## Caching

All endpoints cache responses for 1 hour with automatic revalidation:

- In-memory cache for MCP server (cleared hourly)
- HTTP cache headers for static endpoints
- Search results cached per query+source+limit combination

## Practical Tips

1. **Start with search** - Always search before fetching to find the right content
2. **Use source filters** - When you know the content type (docs, academy, blog), filter for better results
3. **Batch similar requests** - JSON-RPC supports batch requests to reduce round trips
4. **Handle truncation** - Long pages may be truncated; use the URL to get the full version
5. **Cache intelligently** - Cache frequently accessed pages in your application layer

## Search Scoring Algorithm

The MCP server uses keyword-based scoring:

- **Title match**: 20 points
- **Description match**: 10 points
- **URL match**: 5 points
- **Exact phrase match**: +30 bonus points
- **Case-insensitive matching**

Results are sorted by score (highest first).

## Standards

- [llms.txt](https://llmstxt.org/) - AI sitemap standard
- [Model Context Protocol](https://modelcontextprotocol.io/) - Anthropic's standard for AI tool access
- [JSON-RPC 2.0](https://www.jsonrpc.org/specification) - MCP server protocol
